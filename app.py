"""
CLAP (Contrastive Language-Audio Pretraining) Application
Streamlit-based web application for audio-text understanding using CLAP models.
"""

import streamlit as st
import time
import os
import tempfile
from typing import Dict, List, Any, Optional
import warnings
warnings.filterwarnings('ignore')

# Import custom modules
from clap_model import CLAPModelManager, AudioAnalyzer
from visualization_manager import CLAPVisualizationManager
from sample_audio_manager import SampleAudioManager

# Page configuration
st.set_page_config(
    page_title="CLAP Audio-Text Understanding",
    page_icon="ğŸµ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    .feature-card {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin: 0.5rem 0;
        border: 2px solid transparent;
        transition: all 0.3s ease;
    }
    .feature-card:hover {
        border-color: #667eea;
        transform: translateY(-2px);
    }
    .stButton > button {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 5px;
        padding: 0.5rem 1rem;
        font-weight: bold;
        width: 100%;
    }
    .stButton > button:hover {
        background: linear-gradient(90deg, #5a6fd8 0%, #6a4190 100%);
    }
    .audio-player {
        margin: 1rem 0;
        padding: 1rem;
        background: #f8f9fa;
        border-radius: 10px;
    }
    .similarity-score {
        font-size: 1.2em;
        font-weight: bold;
        padding: 0.5rem;
        border-radius: 5px;
        text-align: center;
        margin: 0.5rem 0;
    }
    .high-similarity {
        background: #d4edda;
        color: #155724;
        border: 1px solid #c3e6cb;
    }
    .medium-similarity {
        background: #fff3cd;
        color: #856404;
        border: 1px solid #ffeaa7;
    }
    .low-similarity {
        background: #f8d7da;
        color: #721c24;
        border: 1px solid #f5c6cb;
    }
</style>
""", unsafe_allow_html=True)


class CLAPApp:
    """CLAP Application for audio-text understanding"""
    
    def __init__(self):
        """Initialize the application"""
        self.clap_manager = CLAPModelManager()
        self.audio_analyzer = AudioAnalyzer()
        self.viz_manager = CLAPVisualizationManager()
        self.sample_audio_manager = SampleAudioManager()
        
        # Initialize session state
        if 'audio_file' not in st.session_state:
            st.session_state.audio_file = None
        if 'audio_path' not in st.session_state:
            st.session_state.audio_path = None
        if 'model_loaded' not in st.session_state:
            st.session_state.model_loaded = False
        if 'similarity_results' not in st.session_state:
            st.session_state.similarity_results = {}
        if 'audio_features' not in st.session_state:
            st.session_state.audio_features = {}
        if 'processing_times' not in st.session_state:
            st.session_state.processing_times = {}
    
    def run(self):
        """Run the application"""
        self._display_header()
        self._display_sidebar()
        self._display_main_content()
    
    def _display_header(self):
        """Display the application header"""
        st.markdown("""
        <div class="main-header">
            <h1>ğŸµ CLAP Audio-Text Understanding</h1>
            <p>Contrastive Language-Audio Pretraining for Audio-Text Understanding</p>
        </div>
        """, unsafe_allow_html=True)
    
    def _display_sidebar(self):
        """Display the sidebar with model loading and audio upload"""
        st.sidebar.title("ğŸ”§ è¨­å®š")
        
        # Model loading section
        st.sidebar.subheader("ğŸ¤– ãƒ¢ãƒ‡ãƒ«è¨­å®š")
        
        if not st.session_state.model_loaded:
            if st.sidebar.button("CLAPãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"):
                with st.spinner("CLAPãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
                    start_time = time.time()
                    success = self.clap_manager.load_model()
                    load_time = time.time() - start_time
                    
                    if success:
                        st.session_state.model_loaded = True
                        st.session_state.processing_times["Model Loading"] = load_time
                        st.sidebar.success(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº† ({load_time:.2f}ç§’)")
                    else:
                        st.sidebar.error("âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
        else:
            st.sidebar.success("âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿æ¸ˆã¿")
            
            # Model info
            model_info = self.clap_manager.get_model_info()
            st.sidebar.subheader("ğŸ“Š ãƒ¢ãƒ‡ãƒ«æƒ…å ±")
            st.sidebar.write(f"**ãƒ¢ãƒ‡ãƒ«:** {model_info['model_name']}")
            st.sidebar.write(f"**ãƒ‡ãƒã‚¤ã‚¹:** {model_info['device']}")
            st.sidebar.write(f"**ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ:** {model_info['sample_rate']} Hz")
            if 'model_parameters' in model_info:
                st.sidebar.write(f"**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°:** {model_info['model_parameters']:,}")
        
        # Audio upload section
        st.sidebar.subheader("ğŸµ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«")
        
        uploaded_file = st.sidebar.file_uploader(
            "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=['wav', 'mp3', 'flac', 'm4a', 'ogg'],
            help="ã‚µãƒãƒ¼ãƒˆå½¢å¼: WAV, MP3, FLAC, M4A, OGG"
        )
        
        if uploaded_file is not None:
            # Save uploaded file temporarily
            with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                st.session_state.audio_path = tmp_file.name
                st.session_state.audio_file = uploaded_file
            
            # Display audio player
            st.sidebar.audio(uploaded_file, format=f"audio/{uploaded_file.name.split('.')[-1]}")
            
            # Audio file info
            if st.session_state.audio_path:
                audio_info = self.audio_analyzer.analyze_audio_file(st.session_state.audio_path)
                if audio_info:
                    st.sidebar.subheader("ğŸ“‹ éŸ³å£°æƒ…å ±")
                    st.sidebar.write(f"**é•·ã•:** {audio_info['duration']:.2f}ç§’")
                    st.sidebar.write(f"**ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ:** {audio_info['sample_rate']} Hz")
                    st.sidebar.write(f"**ãƒãƒ£ãƒ³ãƒãƒ«æ•°:** {audio_info['channels']}")
                    st.sidebar.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º:** {audio_info['file_size_mb']:.2f} MB")
                    
                    # Store audio features
                    st.session_state.audio_features = audio_info
        
        # Sample audio files
        st.sidebar.subheader("ğŸµ ã‚µãƒ³ãƒ—ãƒ«éŸ³å£°")
        
        # Category selection
        categories = self.sample_audio_manager.get_all_categories()
        selected_category = st.sidebar.selectbox(
            "ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ",
            ["ã™ã¹ã¦"] + categories,
            help="éŸ³å£°ã®ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠã—ã¦ãã ã•ã„"
        )
        
        # Get audio files by category
        if selected_category == "ã™ã¹ã¦":
            available_samples = self.sample_audio_manager.get_sample_audio_list()
        else:
            available_samples = self.sample_audio_manager.get_audio_by_category(selected_category)
        
        selected_sample = st.sidebar.selectbox(
            "ã‚µãƒ³ãƒ—ãƒ«éŸ³å£°ã‚’é¸æŠ",
            ["ãªã—"] + available_samples,
            help="ãƒ†ã‚¹ãƒˆç”¨ã®éŸ³å£°ã‚µãƒ³ãƒ—ãƒ«ã‚’é¸æŠã§ãã¾ã™"
        )
        
        # Display sample info
        if selected_sample != "ãªã—":
            sample_info = self.sample_audio_manager.get_sample_audio_info(selected_sample)
            if sample_info:
                st.sidebar.info(f"**èª¬æ˜:** {sample_info['description']}")
                st.sidebar.info(f"**ã‚«ãƒ†ã‚´ãƒª:** {sample_info['category']}")
        
        if selected_sample != "ãªã—":
            col1, col2 = st.sidebar.columns(2)
            with col1:
                if st.button("ã‚µãƒ³ãƒ—ãƒ«éŸ³å£°ã‚’èª­ã¿è¾¼ã¿"):
                    self._load_sample_audio(selected_sample)
            with col2:
                if st.button("åˆæˆéŸ³å£°ã‚’ä½œæˆ"):
                    self._create_synthetic_audio()
        
        # Synthetic audio section
        st.sidebar.subheader("ğŸ”§ åˆæˆéŸ³å£°")
        synthetic_types = self.sample_audio_manager.get_synthetic_audio_types()
        selected_synthetic = st.sidebar.selectbox(
            "åˆæˆéŸ³å£°ã‚¿ã‚¤ãƒ—",
            ["ãªã—"] + synthetic_types,
            help="ãƒ†ã‚¹ãƒˆç”¨ã®åˆæˆéŸ³å£°ã‚’ä½œæˆã§ãã¾ã™"
        )
        
        if selected_synthetic != "ãªã—":
            duration = st.sidebar.slider("é•·ã• (ç§’)", 1.0, 10.0, 3.0, 0.5)
            if st.sidebar.button("åˆæˆéŸ³å£°ã‚’ä½œæˆ"):
                self._create_synthetic_audio(selected_synthetic, duration)
        
        # Text queries section
        st.sidebar.subheader("ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆã‚¯ã‚¨ãƒª")
        
        # Custom query input
        custom_query = st.sidebar.text_input(
            "ã‚«ã‚¹ã‚¿ãƒ ã‚¯ã‚¨ãƒªã‚’å…¥åŠ›",
            placeholder="ä¾‹: éŸ³æ¥½ãŒæµã‚Œã¦ã„ã‚‹ã€äººã®è©±ã—å£°ã€é³¥ã®é³´ãå£°...",
            help="ç‹¬è‡ªã®ãƒ†ã‚­ã‚¹ãƒˆã‚¯ã‚¨ãƒªã‚’å…¥åŠ›ã§ãã¾ã™"
        )
        
        # Category-based query suggestions
        if selected_category != "ã™ã¹ã¦" and selected_category in categories:
            category_queries = self.sample_audio_manager.get_category_queries(selected_category)
            st.sidebar.subheader(f"ğŸ¯ {selected_category}é–¢é€£ã‚¯ã‚¨ãƒª")
            selected_category_queries = st.sidebar.multiselect(
                f"{selected_category}é–¢é€£ã®ã‚¯ã‚¨ãƒªã‚’é¸æŠ",
                category_queries,
                help=f"{selected_category}ã‚«ãƒ†ã‚´ãƒªã«é©ã—ãŸã‚¯ã‚¨ãƒªã§ã™"
            )
        else:
            selected_category_queries = []
        
        # General sample queries
        st.sidebar.subheader("ğŸ“‹ ä¸€èˆ¬çš„ãªã‚¯ã‚¨ãƒª")
        general_queries = [
            "éŸ³æ¥½ãŒæµã‚Œã¦ã„ã‚‹",
            "äººã®è©±ã—å£°",
            "é³¥ã®é³´ãå£°",
            "è»Šã®ã‚¨ãƒ³ã‚¸ãƒ³éŸ³",
            "é›¨ã®éŸ³",
            "ç¬‘ã„å£°",
            "æ‹æ‰‹",
            "ãƒ‰ã‚¢ãŒé–‰ã¾ã‚‹éŸ³",
            "é›»è©±ã®ç€ä¿¡éŸ³",
            "ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã®ã‚¿ã‚¤ãƒ”ãƒ³ã‚°éŸ³",
            "çŠ¬ã®é³´ãå£°",
            "çŒ«ã®é³´ãå£°",
            "é¢¨ã®éŸ³",
            "æ³¢ã®éŸ³",
            "é›·ã®éŸ³",
            "æ™‚è¨ˆã®éŸ³",
            "ãƒ‰ã‚¢ãƒ™ãƒ«",
            "ã‚¢ãƒ©ãƒ¼ãƒ éŸ³",
            "æ¥½å™¨ã®éŸ³",
            "æ©Ÿæ¢°ã®éŸ³"
        ]
        
        selected_general_queries = st.sidebar.multiselect(
            "ä¸€èˆ¬çš„ãªã‚¯ã‚¨ãƒªã‚’é¸æŠ",
            general_queries,
            default=general_queries[:3],
            help="è¤‡æ•°ã®ã‚¯ã‚¨ãƒªã‚’é¸æŠã§ãã¾ã™"
        )
        
        # Combine all queries
        all_queries = []
        if custom_query.strip():
            all_queries.append(custom_query.strip())
        all_queries.extend(selected_category_queries)
        all_queries.extend(selected_general_queries)
        
        # Display selected queries
        if all_queries:
            st.sidebar.subheader("ğŸ“‹ åˆ†æå¯¾è±¡ã‚¯ã‚¨ãƒª")
            for i, query in enumerate(all_queries, 1):
                st.sidebar.write(f"{i}. {query}")
        
        if st.sidebar.button("é¸æŠã—ãŸã‚¯ã‚¨ãƒªã§åˆ†æ", help="éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã‚¯ã‚¨ãƒªã‚’åˆ†æã—ã¾ã™"):
            if st.session_state.audio_path and st.session_state.model_loaded:
                if all_queries:
                    self._analyze_audio_text_similarity(all_queries)
                else:
                    st.sidebar.warning("åˆ†æã™ã‚‹ã‚¯ã‚¨ãƒªã‚’å…¥åŠ›ã¾ãŸã¯é¸æŠã—ã¦ãã ã•ã„")
            else:
                st.sidebar.warning("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ¢ãƒ‡ãƒ«ã®ä¸¡æ–¹ãŒå¿…è¦ã§ã™")
    
    def _display_main_content(self):
        """Display the main content area"""
        if not st.session_state.model_loaded:
            st.warning("âš ï¸ ã¾ãšã‚µã‚¤ãƒ‰ãƒãƒ¼ã§CLAPãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
            return
        
        if not st.session_state.audio_path:
            st.warning("âš ï¸ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            return
        
        # Create tabs
        tab1, tab2, tab3, tab4 = st.tabs([
            "ğŸµ éŸ³å£°åˆ†æ", 
            "ğŸ” ãƒ†ã‚­ã‚¹ãƒˆ-éŸ³å£°ãƒãƒƒãƒãƒ³ã‚°", 
            "ğŸ“Š å¯è¦–åŒ–", 
            "âš™ï¸ ãƒ‡ãƒãƒƒã‚°æƒ…å ±"
        ])
        
        with tab1:
            self._display_audio_analysis_tab()
        
        with tab2:
            self._display_text_audio_matching_tab()
        
        with tab3:
            self._display_visualization_tab()
        
        with tab4:
            self._display_debug_tab()
    
    def _display_audio_analysis_tab(self):
        """Display audio analysis tab"""
        st.header("ğŸµ éŸ³å£°åˆ†æ")
        
        if st.session_state.audio_features:
            # Audio features display
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("ğŸ“‹ åŸºæœ¬æƒ…å ±")
                features = st.session_state.audio_features
                
                st.metric("é•·ã•", f"{features['duration']:.2f}ç§’")
                st.metric("ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ", f"{features['sample_rate']} Hz")
                st.metric("ãƒãƒ£ãƒ³ãƒãƒ«æ•°", features['channels'])
                st.metric("ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º", f"{features['file_size_mb']:.2f} MB")
            
            with col2:
                st.subheader("ğŸ›ï¸ ã‚¹ãƒšã‚¯ãƒˆãƒ«ç‰¹å¾´")
                st.metric("ã‚¹ãƒšã‚¯ãƒˆãƒ«é‡å¿ƒ", f"{features.get('spectral_centroid_mean', 0):.2f}")
                st.metric("ã‚¹ãƒšã‚¯ãƒˆãƒ«å¸¯åŸŸå¹…", f"{features.get('spectral_bandwidth_mean', 0):.2f}")
                st.metric("ã‚¼ãƒ­ã‚¯ãƒ­ã‚¹ç‡", f"{features.get('zero_crossing_rate_mean', 0):.4f}")
                st.metric("RMSã‚¨ãƒãƒ«ã‚®ãƒ¼", f"{features.get('rms_mean', 0):.4f}")
            
            # Audio visualizations
            st.subheader("ğŸ“ˆ éŸ³å£°å¯è¦–åŒ–")
            
            col1, col2 = st.columns(2)
            
            with col1:
                # Waveform
                waveform_fig = self.viz_manager.create_audio_waveform(st.session_state.audio_path)
                st.plotly_chart(waveform_fig, use_container_width=True)
            
            with col2:
                # Spectrogram
                spectrogram_fig = self.viz_manager.create_spectrogram(st.session_state.audio_path)
                st.plotly_chart(spectrogram_fig, use_container_width=True)
            
            # MFCC and Radar chart
            col1, col2 = st.columns(2)
            
            with col1:
                # MFCC
                mfcc_fig = self.viz_manager.create_mfcc_heatmap(st.session_state.audio_path)
                st.plotly_chart(mfcc_fig, use_container_width=True)
            
            with col2:
                # Radar chart
                radar_fig = self.viz_manager.create_audio_features_radar(st.session_state.audio_features)
                st.plotly_chart(radar_fig, use_container_width=True)
    
    def _display_text_audio_matching_tab(self):
        """Display text-audio matching tab"""
        st.header("ğŸ” ãƒ†ã‚­ã‚¹ãƒˆ-éŸ³å£°ãƒãƒƒãƒãƒ³ã‚°")
        
        # Custom text input
        st.subheader("ğŸ“ ã‚«ã‚¹ã‚¿ãƒ ã‚¯ã‚¨ãƒª")
        
        col1, col2 = st.columns([3, 1])
        
        with col1:
            custom_text = st.text_input(
                "ãƒ†ã‚­ã‚¹ãƒˆã‚¯ã‚¨ãƒªã‚’å…¥åŠ›",
                placeholder="ä¾‹: éŸ³æ¥½ãŒæµã‚Œã¦ã„ã‚‹ã€äººã®è©±ã—å£°ã€é³¥ã®é³´ãå£°..."
            )
        
        with col2:
            if st.button("åˆ†æå®Ÿè¡Œ"):
                if custom_text:
                    self._analyze_single_query(custom_text)
        
        # Display similarity results
        if st.session_state.similarity_results:
            st.subheader("ğŸ“Š é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢")
            
            # Sort results by similarity score
            sorted_results = sorted(
                st.session_state.similarity_results.items(),
                key=lambda x: x[1],
                reverse=True
            )
            
            # Display results
            for text, score in sorted_results:
                # Determine similarity level
                if score >= 0.6:
                    css_class = "high-similarity"
                    emoji = "ğŸŸ¢"
                elif score >= 0.3:
                    css_class = "medium-similarity"
                    emoji = "ğŸŸ¡"
                else:
                    css_class = "low-similarity"
                    emoji = "ğŸ”´"
                
                st.markdown(f"""
                <div class="similarity-score {css_class}">
                    {emoji} <strong>{text}</strong>: {score:.3f}
                </div>
                """, unsafe_allow_html=True)
            
            # Similarity chart
            similarity_fig = self.viz_manager.create_similarity_bar_chart(st.session_state.similarity_results)
            st.plotly_chart(similarity_fig, use_container_width=True)
    
    def _display_visualization_tab(self):
        """Display visualization tab"""
        st.header("ğŸ“Š å¯è¦–åŒ–")
        
        if st.session_state.audio_path and st.session_state.audio_features:
            # Comprehensive dashboard
            st.subheader("ğŸ›ï¸ éŸ³å£°åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
            dashboard_fig = self.viz_manager.create_audio_analysis_dashboard(
                st.session_state.audio_path,
                st.session_state.audio_features
            )
            st.plotly_chart(dashboard_fig, use_container_width=True)
    
    def _display_debug_tab(self):
        """Display debug information tab"""
        st.header("âš™ï¸ ãƒ‡ãƒãƒƒã‚°æƒ…å ±")
        
        # Model information
        st.subheader("ğŸ¤– ãƒ¢ãƒ‡ãƒ«æƒ…å ±")
        model_info = self.clap_manager.get_model_info()
        model_info_fig = self.viz_manager.create_model_info_display(model_info)
        st.plotly_chart(model_info_fig, use_container_width=True)
        
        # Performance metrics
        if st.session_state.processing_times:
            st.subheader("â±ï¸ å‡¦ç†æ™‚é–“")
            performance_fig = self.viz_manager.create_performance_metrics(st.session_state.processing_times)
            st.plotly_chart(performance_fig, use_container_width=True)
        
        # Audio features details
        if st.session_state.audio_features:
            st.subheader("ğŸµ éŸ³å£°ç‰¹å¾´è©³ç´°")
            st.json(st.session_state.audio_features)
    
    def _analyze_audio_text_similarity(self, text_queries: List[str]):
        """Analyze similarity between audio and text queries
        
        Args:
            text_queries: List of text queries to analyze
        """
        if not st.session_state.audio_path or not st.session_state.model_loaded:
            return
        
        with st.spinner("éŸ³å£°-ãƒ†ã‚­ã‚¹ãƒˆé¡ä¼¼åº¦ã‚’åˆ†æä¸­..."):
            start_time = time.time()
            
            # Perform audio-text matching
            results = self.clap_manager.audio_text_matching(
                st.session_state.audio_path,
                text_queries
            )
            
            processing_time = time.time() - start_time
            st.session_state.processing_times["Audio-Text Matching"] = processing_time
            
            # Store results
            st.session_state.similarity_results = results
            
            st.success(f"âœ… åˆ†æå®Œäº† ({processing_time:.2f}ç§’)")
    
    def _analyze_single_query(self, text_query: str):
        """Analyze single text query
        
        Args:
            text_query: Single text query to analyze
        """
        if not st.session_state.audio_path or not st.session_state.model_loaded:
            return
        
        with st.spinner("å˜ä¸€ã‚¯ã‚¨ãƒªã‚’åˆ†æä¸­..."):
            start_time = time.time()
            
            # Perform audio-text matching
            results = self.clap_manager.audio_text_matching(
                st.session_state.audio_path,
                [text_query]
            )
            
            processing_time = time.time() - start_time
            st.session_state.processing_times["Single Query Analysis"] = processing_time
            
            # Update results
            st.session_state.similarity_results.update(results)
            
            st.success(f"âœ… åˆ†æå®Œäº† ({processing_time:.2f}ç§’)")
    
    def _load_sample_audio(self, audio_name: str):
        """Load sample audio file
        
        Args:
            audio_name: Name of the sample audio to load
        """
        try:
            with st.spinner(f"{audio_name} ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                audio_path = self.sample_audio_manager.download_sample_audio(audio_name)
                
                if audio_path:
                    st.session_state.audio_path = audio_path
                    
                    # Load audio for display
                    import requests
                    sample_info = self.sample_audio_manager.get_sample_audio_info(audio_name)
                    if sample_info:
                        response = requests.get(sample_info["url"])
                        if response.status_code == 200:
                            st.sidebar.audio(response.content, format="audio/wav")
                    
                    # Update audio features
                    audio_info = self.audio_analyzer.analyze_audio_file(audio_path)
                    if audio_info:
                        st.session_state.audio_features = audio_info
                    
                    st.sidebar.success(f"âœ… {audio_name} ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼")
                else:
                    st.sidebar.error(f"âŒ {audio_name} ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
        except Exception as e:
            st.sidebar.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def _create_synthetic_audio(self, audio_type: str = None, duration: float = 3.0):
        """Create synthetic audio for testing
        
        Args:
            audio_type: Type of synthetic audio to create
            duration: Duration in seconds
        """
        if audio_type is None:
            audio_type = "sine_wave"
        
        try:
            with st.spinner(f"{audio_type} ã‚’ä½œæˆä¸­..."):
                audio_path = self.sample_audio_manager.create_synthetic_audio(
                    audio_type, duration
                )
                
                if audio_path:
                    st.session_state.audio_path = audio_path
                    
                    # Load audio for display
                    with open(audio_path, 'rb') as f:
                        audio_data = f.read()
                    st.sidebar.audio(audio_data, format="audio/wav")
                    
                    # Update audio features
                    audio_info = self.audio_analyzer.analyze_audio_file(audio_path)
                    if audio_info:
                        st.session_state.audio_features = audio_info
                    
                    st.sidebar.success(f"âœ… {audio_type} ã‚’ä½œæˆã—ã¾ã—ãŸï¼")
                else:
                    st.sidebar.error(f"âŒ {audio_type} ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
        except Exception as e:
            st.sidebar.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")


def main():
    """Main function"""
    app = CLAPApp()
    app.run()


if __name__ == "__main__":
    main() 