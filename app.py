"""
CLAP (Contrastive Language-Audio Pretraining) Application
Streamlit-based web application for audio-text understanding using CLAP models.
"""

import streamlit as st
import time
import os
import tempfile
import pandas as pd
from typing import Dict, List, Any, Optional
import warnings
warnings.filterwarnings('ignore')

# Import custom modules
from clap_model import CLAPModelManager, AudioAnalyzer
from visualization_manager import CLAPVisualizationManager
from sample_audio_manager import SampleAudioManager

# Page configuration
st.set_page_config(
    page_title="CLAP Audio-Text Understanding",
    page_icon="üéµ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    .feature-card {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin: 0.5rem 0;
        border: 2px solid transparent;
        transition: all 0.3s ease;
    }
    .feature-card:hover {
        border-color: #667eea;
        transform: translateY(-2px);
    }
    .stButton > button {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 5px;
        padding: 0.5rem 1rem;
        font-weight: bold;
        width: 100%;
    }
    .stButton > button:hover {
        background: linear-gradient(90deg, #5a6fd8 0%, #6a4190 100%);
    }
    .audio-player {
        margin: 1rem 0;
        padding: 1rem;
        background: #f8f9fa;
        border-radius: 10px;
    }
    .similarity-score {
        font-size: 1.2em;
        font-weight: bold;
        padding: 0.5rem;
        border-radius: 5px;
        text-align: center;
        margin: 0.5rem 0;
    }
    .high-similarity {
        background: #d4edda;
        color: #155724;
        border: 1px solid #c3e6cb;
    }
    .medium-similarity {
        background: #fff3cd;
        color: #856404;
        border: 1px solid #ffeaa7;
    }
    .low-similarity {
        background: #f8d7da;
        color: #721c24;
        border: 1px solid #f5c6cb;
    }
</style>
""", unsafe_allow_html=True)


class CLAPApp:
    """CLAP Application for audio-text understanding"""
    
    def __init__(self):
        """Initialize the application"""
        self.clap_manager = CLAPModelManager()
        self.audio_analyzer = AudioAnalyzer()
        self.viz_manager = CLAPVisualizationManager()
        self.sample_audio_manager = SampleAudioManager()
        
        # Initialize audio search engine
        self.search_engine = None  # Will be initialized after model loading
        
        # Initialize session state
        if 'audio_file' not in st.session_state:
            st.session_state.audio_file = None
        if 'audio_path' not in st.session_state:
            st.session_state.audio_path = None
        if 'model_loaded' not in st.session_state:
            st.session_state.model_loaded = False
        if 'similarity_results' not in st.session_state:
            st.session_state.similarity_results = {}
        if 'audio_features' not in st.session_state:
            st.session_state.audio_features = {}
        if 'processing_times' not in st.session_state:
            st.session_state.processing_times = {}
        if 'detection_timing_data' not in st.session_state:
            st.session_state.detection_timing_data = {}
        if 'search_results' not in st.session_state:
            st.session_state.search_results = {}
        if 'search_engine_initialized' not in st.session_state:
            st.session_state.search_engine_initialized = False
        if 'matching_success_analysis' not in st.session_state:
            st.session_state.matching_success_analysis = {}
    
    def run(self):
        """Run the application"""
        self._display_header()
        self._display_sidebar()
        self._display_main_content()
    
    def _display_header(self):
        """Display the application header"""
        st.markdown("""
        <div class="main-header">
            <h1>üéµ CLAP Audio-Text Understanding</h1>
            <p>Contrastive Language-Audio Pretraining for Audio-Text Understanding</p>
        </div>
        """, unsafe_allow_html=True)
    
    def _display_sidebar(self):
        """Display the sidebar with model loading and audio upload"""
        st.sidebar.title("üîß Ë®≠ÂÆö")
        
        # Model loading section
        st.sidebar.subheader("ü§ñ „É¢„Éá„É´Ë®≠ÂÆö")
        
        if not st.session_state.model_loaded:
            if st.sidebar.button("CLAP„É¢„Éá„É´„ÇíË™≠„ÅøËæº„Åø"):
                with st.spinner("CLAP„É¢„Éá„É´„ÇíË™≠„ÅøËæº„Åø‰∏≠..."):
                    start_time = time.time()
                    success = self.clap_manager.load_model()
                    load_time = time.time() - start_time
                    
                    if success:
                        st.session_state.model_loaded = True
                        st.session_state.processing_times["Model Loading"] = load_time
                        # Initialize search engine after model loading
                        from clap_model import AudioSearchEngine
                        self.search_engine = AudioSearchEngine(self.clap_manager)
                        st.session_state.search_engine_initialized = True
                        st.sidebar.success(f"‚úÖ „É¢„Éá„É´Ë™≠„ÅøËæº„ÅøÂÆå‰∫Ü ({load_time:.2f}Áßí)")
                        st.sidebar.success("üîç Èü≥Â£∞Ê§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅåÂàùÊúüÂåñ„Åï„Çå„Åæ„Åó„Åü")
                    else:
                        st.sidebar.error("‚ùå „É¢„Éá„É´Ë™≠„ÅøËæº„Åø„Å´Â§±Êïó„Åó„Åæ„Åó„Åü")
        else:
            st.sidebar.success("‚úÖ „É¢„Éá„É´Ë™≠„ÅøËæº„ÅøÊ∏à„Åø")
            
            # Initialize search engine if not already done
            if self.search_engine is None and not st.session_state.search_engine_initialized:
                try:
                    from clap_model import AudioSearchEngine
                    self.search_engine = AudioSearchEngine(self.clap_manager)
                    st.session_state.search_engine_initialized = True
                    st.sidebar.success("üîç Èü≥Â£∞Ê§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅåÂàùÊúüÂåñ„Åï„Çå„Åæ„Åó„Åü")
                except Exception as e:
                    st.sidebar.error(f"‚ùå Ê§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅÆÂàùÊúüÂåñ„Å´Â§±Êïó: {str(e)}")
            
            # Model info
            model_info = self.clap_manager.get_model_info()
            st.sidebar.subheader("üìä „É¢„Éá„É´ÊÉÖÂ†±")
            st.sidebar.write(f"**„É¢„Éá„É´:** {model_info['model_name']}")
            st.sidebar.write(f"**„Éá„Éê„Ç§„Çπ:** {model_info['device']}")
            st.sidebar.write(f"**„Çµ„É≥„Éó„É´„É¨„Éº„Éà:** {model_info['sample_rate']} Hz")
            if 'model_parameters' in model_info:
                st.sidebar.write(f"**„Éë„É©„É°„Éº„ÇøÊï∞:** {model_info['model_parameters']:,}")
        
        # Audio upload section
        st.sidebar.subheader("üéµ Èü≥Â£∞„Éï„Ç°„Ç§„É´")
        
        uploaded_file = st.sidebar.file_uploader(
            "Èü≥Â£∞„Éï„Ç°„Ç§„É´„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ",
            type=['wav', 'mp3', 'flac', 'm4a', 'ogg'],
            help="„Çµ„Éù„Éº„ÉàÂΩ¢Âºè: WAV, MP3, FLAC, M4A, OGG"
        )
        
        if uploaded_file is not None:
            # Save uploaded file temporarily
            with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                st.session_state.audio_path = tmp_file.name
                st.session_state.audio_file = uploaded_file
            
            # Validate audio file
            if st.session_state.audio_path:
                with st.spinner("Èü≥Â£∞„Éï„Ç°„Ç§„É´„ÇíÊ§úË®º‰∏≠..."):
                    validation = self.audio_analyzer.validate_audio_file(st.session_state.audio_path)
                
                # Display validation results
                if not validation["is_valid"]:
                    st.sidebar.error("‚ùå Èü≥Â£∞„Éï„Ç°„Ç§„É´„ÅÆÊ§úË®º„Å´Â§±Êïó„Åó„Åæ„Åó„Åü")
                    with st.sidebar.expander("üîç Ê§úË®º„Ç®„É©„ÉºË©≥Á¥∞"):
                        for error in validation["errors"]:
                            st.error(f"‚Ä¢ {error}")
                    return
                
                # Show warnings if any
                if validation["warnings"]:
                    st.sidebar.warning("‚ö†Ô∏è Èü≥Â£∞„Éï„Ç°„Ç§„É´„Å´Ë≠¶Âëä„Åå„ÅÇ„Çä„Åæ„Åô")
                    with st.sidebar.expander("‚ö†Ô∏è Ë≠¶ÂëäË©≥Á¥∞"):
                        for warning in validation["warnings"]:
                            st.warning(f"‚Ä¢ {warning}")
                
                # Display audio player
                st.sidebar.audio(uploaded_file, format=f"audio/{uploaded_file.name.split('.')[-1]}")
                
                # Audio file info
                try:
                    audio_info = self.audio_analyzer.analyze_audio_file(st.session_state.audio_path)
                    if audio_info and audio_info.get('duration', 0) > 0:
                        st.sidebar.subheader("üìã Èü≥Â£∞ÊÉÖÂ†±")
                        st.sidebar.write(f"**Èï∑„Åï:** {audio_info.get('duration', 0):.2f}Áßí")
                        st.sidebar.write(f"**„Çµ„É≥„Éó„É´„É¨„Éº„Éà:** {audio_info.get('sample_rate', 0)} Hz")
                        st.sidebar.write(f"**„ÉÅ„É£„É≥„Éç„É´Êï∞:** {audio_info.get('channels', 0)}")
                        st.sidebar.write(f"**„Éï„Ç°„Ç§„É´„Çµ„Ç§„Ç∫:** {audio_info.get('file_size_mb', 0):.2f} MB")
                        
                        # Store audio features
                        st.session_state.audio_features = audio_info
                        st.sidebar.success("‚úÖ Èü≥Â£∞„Éï„Ç°„Ç§„É´„ÅåÊ≠£Â∏∏„Å´Ë™≠„ÅøËæº„Åæ„Çå„Åæ„Åó„Åü")
                    else:
                        st.sidebar.warning("‚ö†Ô∏è Èü≥Â£∞„Éï„Ç°„Ç§„É´„ÅÆÂàÜÊûê„Å´Â§±Êïó„Åó„Åæ„Åó„Åü")
                except Exception as e:
                    st.sidebar.error(f"‚ùå Èü≥Â£∞ÂàÜÊûê„Ç®„É©„Éº: {str(e)}")
                    import traceback
                    with st.sidebar.expander("Ë©≥Á¥∞„Ç®„É©„ÉºÊÉÖÂ†±"):
                        st.code(traceback.format_exc())
        
        # Sample audio files
        st.sidebar.subheader("üéµ „Çµ„É≥„Éó„É´Èü≥Â£∞")
        
        # Category selection
        categories = self.sample_audio_manager.get_all_categories()
        selected_category = st.sidebar.selectbox(
            "„Ç´„ÉÜ„Ç¥„É™„ÇíÈÅ∏Êäû",
            ["„Åô„Åπ„Å¶"] + categories,
            help="Èü≥Â£∞„ÅÆ„Ç´„ÉÜ„Ç¥„É™„ÇíÈÅ∏Êäû„Åó„Å¶„Åè„Å†„Åï„ÅÑ"
        )
        
        # Get audio files by category
        if selected_category == "„Åô„Åπ„Å¶":
            available_samples = self.sample_audio_manager.get_sample_audio_list()
        else:
            available_samples = self.sample_audio_manager.get_audio_by_category(selected_category)
        
        selected_sample = st.sidebar.selectbox(
            "„Çµ„É≥„Éó„É´Èü≥Â£∞„ÇíÈÅ∏Êäû",
            ["„Å™„Åó"] + available_samples,
            help="„ÉÜ„Çπ„ÉàÁî®„ÅÆÈü≥Â£∞„Çµ„É≥„Éó„É´„ÇíÈÅ∏Êäû„Åß„Åç„Åæ„Åô"
        )
        
        # Display sample info
        if selected_sample != "„Å™„Åó":
            sample_info = self.sample_audio_manager.get_sample_audio_info(selected_sample)
            if sample_info:
                st.sidebar.info(f"**Ë™¨Êòé:** {sample_info['description']}")
                st.sidebar.info(f"**„Ç´„ÉÜ„Ç¥„É™:** {sample_info['category']}")
        
        if selected_sample != "„Å™„Åó":
            col1, col2 = st.sidebar.columns(2)
            with col1:
                if st.button("„Çµ„É≥„Éó„É´Èü≥Â£∞„ÇíË™≠„ÅøËæº„Åø"):
                    self._load_sample_audio(selected_sample)
            with col2:
                if st.button("ÂêàÊàêÈü≥Â£∞„Çí‰ΩúÊàê"):
                    self._create_synthetic_audio()
        
        # Synthetic audio section
        st.sidebar.subheader("üîß ÂêàÊàêÈü≥Â£∞")
        synthetic_types = self.sample_audio_manager.get_synthetic_audio_types()
        selected_synthetic = st.sidebar.selectbox(
            "ÂêàÊàêÈü≥Â£∞„Çø„Ç§„Éó",
            ["„Å™„Åó"] + synthetic_types,
            help="„ÉÜ„Çπ„ÉàÁî®„ÅÆÂêàÊàêÈü≥Â£∞„Çí‰ΩúÊàê„Åß„Åç„Åæ„Åô"
        )
        
        if selected_synthetic != "„Å™„Åó":
            duration = st.sidebar.slider("Èï∑„Åï (Áßí)", 1.0, 10.0, 3.0, 0.5)
            if st.sidebar.button("ÂêàÊàêÈü≥Â£∞„Çí‰ΩúÊàê"):
                self._create_synthetic_audio(selected_synthetic, duration)
        
        # Text queries section
        st.sidebar.subheader("üìù „ÉÜ„Ç≠„Çπ„Éà„ÇØ„Ç®„É™")
        
        # Custom query input
        custom_query = st.sidebar.text_input(
            "„Ç´„Çπ„Çø„É†„ÇØ„Ç®„É™„ÇíÂÖ•Âäõ",
            placeholder="‰æã: Èü≥Ê•Ω„ÅåÊµÅ„Çå„Å¶„ÅÑ„Çã„ÄÅ‰∫∫„ÅÆË©±„ÅóÂ£∞„ÄÅÈ≥•„ÅÆÈ≥¥„ÅçÂ£∞...",
            help="Áã¨Ëá™„ÅÆ„ÉÜ„Ç≠„Çπ„Éà„ÇØ„Ç®„É™„ÇíÂÖ•Âäõ„Åß„Åç„Åæ„Åô"
        )
        
        # Category-based query suggestions
        if selected_category != "„Åô„Åπ„Å¶" and selected_category in categories:
            category_queries = self.sample_audio_manager.get_category_queries(selected_category)
            st.sidebar.subheader(f"üéØ {selected_category}Èñ¢ÈÄ£„ÇØ„Ç®„É™")
            selected_category_queries = st.sidebar.multiselect(
                f"{selected_category}Èñ¢ÈÄ£„ÅÆ„ÇØ„Ç®„É™„ÇíÈÅ∏Êäû",
                category_queries,
                help=f"{selected_category}„Ç´„ÉÜ„Ç¥„É™„Å´ÈÅ©„Åó„Åü„ÇØ„Ç®„É™„Åß„Åô"
            )
        else:
            selected_category_queries = []
        
        # General sample queries
        st.sidebar.subheader("üìã ‰∏ÄËà¨ÁöÑ„Å™„ÇØ„Ç®„É™")
        general_queries = [
            "Èü≥Ê•Ω„ÅåÊµÅ„Çå„Å¶„ÅÑ„Çã",
            "‰∫∫„ÅÆË©±„ÅóÂ£∞",
            "È≥•„ÅÆÈ≥¥„ÅçÂ£∞",
            "Ëªä„ÅÆ„Ç®„É≥„Ç∏„É≥Èü≥",
            "Èõ®„ÅÆÈü≥",
            "Á¨ë„ÅÑÂ£∞",
            "ÊãçÊâã",
            "„Éâ„Ç¢„ÅåÈñâ„Åæ„ÇãÈü≥",
            "ÈõªË©±„ÅÆÁùÄ‰ø°Èü≥",
            "„Ç≠„Éº„Éú„Éº„Éâ„ÅÆ„Çø„Ç§„Éî„É≥„Ç∞Èü≥",
            "Áä¨„ÅÆÈ≥¥„ÅçÂ£∞",
            "Áå´„ÅÆÈ≥¥„ÅçÂ£∞",
            "È¢®„ÅÆÈü≥",
            "Ê≥¢„ÅÆÈü≥",
            "Èõ∑„ÅÆÈü≥",
            "ÊôÇË®à„ÅÆÈü≥",
            "„Éâ„Ç¢„Éô„É´",
            "„Ç¢„É©„Éº„É†Èü≥",
            "Ê•ΩÂô®„ÅÆÈü≥",
            "Ê©üÊ¢∞„ÅÆÈü≥"
        ]
        
        selected_general_queries = st.sidebar.multiselect(
            "‰∏ÄËà¨ÁöÑ„Å™„ÇØ„Ç®„É™„ÇíÈÅ∏Êäû",
            general_queries,
            default=general_queries[:3],
            help="Ë§áÊï∞„ÅÆ„ÇØ„Ç®„É™„ÇíÈÅ∏Êäû„Åß„Åç„Åæ„Åô"
        )
        
        # Combine all queries
        all_queries = []
        if custom_query.strip():
            all_queries.append(custom_query.strip())
        all_queries.extend(selected_category_queries)
        all_queries.extend(selected_general_queries)
        
        # Display selected queries
        if all_queries:
            st.sidebar.subheader("üìã ÂàÜÊûêÂØæË±°„ÇØ„Ç®„É™")
            for i, query in enumerate(all_queries, 1):
                st.sidebar.write(f"{i}. {query}")
        
        col1, col2 = st.sidebar.columns(2)
        with col1:
            if st.button("Âü∫Êú¨ÂàÜÊûê", help="Âü∫Êú¨ÁöÑ„Å™Èü≥Â£∞-„ÉÜ„Ç≠„Çπ„ÉàÈ°û‰ººÂ∫¶ÂàÜÊûê"):
                if st.session_state.audio_path and st.session_state.model_loaded:
                    if all_queries:
                        self._analyze_audio_text_similarity(all_queries)
                    else:
                        st.warning("ÂàÜÊûê„Åô„Çã„ÇØ„Ç®„É™„ÇíÂÖ•Âäõ„Åæ„Åü„ÅØÈÅ∏Êäû„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
                else:
                    st.warning("Èü≥Â£∞„Éï„Ç°„Ç§„É´„Å®„É¢„Éá„É´„ÅÆ‰∏°Êñπ„ÅåÂøÖË¶Å„Åß„Åô")
        
        with col2:
            if st.button("Ë©≥Á¥∞ÂàÜÊûê", help="„Çø„Ç§„Éü„É≥„Ç∞ÊÉÖÂ†±‰ªò„Åç„ÅÆË©≥Á¥∞ÂàÜÊûê"):
                if st.session_state.audio_path and st.session_state.model_loaded:
                    if all_queries:
                        self._analyze_audio_text_similarity_with_timing(all_queries)
                    else:
                        st.warning("ÂàÜÊûê„Åô„Çã„ÇØ„Ç®„É™„ÇíÂÖ•Âäõ„Åæ„Åü„ÅØÈÅ∏Êäû„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
                else:
                    st.warning("Èü≥Â£∞„Éï„Ç°„Ç§„É´„Å®„É¢„Éá„É´„ÅÆ‰∏°Êñπ„ÅåÂøÖË¶Å„Åß„Åô")
    
    def _display_main_content(self):
        """Display the main content area"""
        if not st.session_state.model_loaded:
            st.warning("‚ö†Ô∏è „Åæ„Åö„Çµ„Ç§„Éâ„Éê„Éº„ÅßCLAP„É¢„Éá„É´„ÇíË™≠„ÅøËæº„Çì„Åß„Åè„Å†„Åï„ÅÑ„ÄÇ")
            return
        
        if not st.session_state.audio_path:
            st.warning("‚ö†Ô∏è Èü≥Â£∞„Éï„Ç°„Ç§„É´„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
            return
        
        # Create tabs
        tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
            "üéµ Èü≥Â£∞ÂàÜÊûê", 
            "üîç „ÉÜ„Ç≠„Çπ„Éà-Èü≥Â£∞„Éû„ÉÉ„ÉÅ„É≥„Ç∞", 
            "üîé Èü≥Â£∞Ê§úÁ¥¢", 
            "üìä ÂèØË¶ñÂåñ", 
            "‚è±Ô∏è Ê§úÂá∫„Çø„Ç§„Éü„É≥„Ç∞ÂàÜÊûê",
            "‚öôÔ∏è „Éá„Éê„ÉÉ„Ç∞ÊÉÖÂ†±"
        ])
        
        with tab1:
            self._display_audio_analysis_tab()
        
        with tab2:
            self._display_text_audio_matching_tab()
        
        with tab3:
            self._display_audio_search_tab()
        
        with tab4:
            self._display_visualization_tab()
        
        with tab5:
            self._display_timing_analysis_tab()
        
        with tab6:
            self._display_debug_tab()
    
    def _display_audio_analysis_tab(self):
        """Display audio analysis tab"""
        st.header("üéµ Èü≥Â£∞ÂàÜÊûê")
        
        if st.session_state.audio_features and st.session_state.audio_path:
            try:
                # Audio features display
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("üìã Âü∫Êú¨ÊÉÖÂ†±")
                    features = st.session_state.audio_features
                    
                    st.metric("Èï∑„Åï", f"{features.get('duration', 0):.2f}Áßí")
                    st.metric("„Çµ„É≥„Éó„É´„É¨„Éº„Éà", f"{features.get('sample_rate', 0)} Hz")
                    st.metric("„ÉÅ„É£„É≥„Éç„É´Êï∞", features.get('channels', 0))
                    st.metric("„Éï„Ç°„Ç§„É´„Çµ„Ç§„Ç∫", f"{features.get('file_size_mb', 0):.2f} MB")
                
                with col2:
                    st.subheader("üéõÔ∏è „Çπ„Éö„ÇØ„Éà„É´ÁâπÂæ¥")
                    st.metric("„Çπ„Éö„ÇØ„Éà„É´ÈáçÂøÉ", f"{features.get('spectral_centroid_mean', 0):.2f}")
                    st.metric("„Çπ„Éö„ÇØ„Éà„É´Â∏ØÂüüÂπÖ", f"{features.get('spectral_bandwidth_mean', 0):.2f}")
                    st.metric("„Çº„É≠„ÇØ„É≠„ÇπÁéá", f"{features.get('zero_crossing_rate_mean', 0):.4f}")
                    st.metric("RMS„Ç®„Éç„É´„ÇÆ„Éº", f"{features.get('rms_mean', 0):.4f}")
                
                # Audio visualizations
                st.subheader("üìà Èü≥Â£∞ÂèØË¶ñÂåñ")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    # Waveform
                    st.write("**Ê≥¢ÂΩ¢Ë°®Á§∫**")
                    try:
                        waveform_fig = self.viz_manager.create_audio_waveform(st.session_state.audio_path)
                        st.plotly_chart(waveform_fig, use_container_width=True, key="audio_analysis_waveform")
                    except Exception as e:
                        st.error(f"Ê≥¢ÂΩ¢„ÅÆË°®Á§∫„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {str(e)}")
                        import traceback
                        with st.expander("Ë©≥Á¥∞„Ç®„É©„ÉºÊÉÖÂ†±"):
                            st.code(traceback.format_exc())
                
                with col2:
                    # Spectrogram
                    st.write("**„Çπ„Éö„ÇØ„Éà„É≠„Ç∞„É©„É†**")
                    try:
                        spectrogram_fig = self.viz_manager.create_spectrogram(st.session_state.audio_path)
                        st.plotly_chart(spectrogram_fig, use_container_width=True, key="audio_analysis_spectrogram")
                    except Exception as e:
                        st.error(f"„Çπ„Éö„ÇØ„Éà„É≠„Ç∞„É©„É†„ÅÆË°®Á§∫„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {str(e)}")
                        import traceback
                        with st.expander("Ë©≥Á¥∞„Ç®„É©„ÉºÊÉÖÂ†±"):
                            st.code(traceback.format_exc())
                
                # MFCC and Radar chart
                col1, col2 = st.columns(2)
                
                with col1:
                    # MFCC
                    st.write("**MFCCÁâπÂæ¥Èáè**")
                    try:
                        mfcc_fig = self.viz_manager.create_mfcc_heatmap(st.session_state.audio_path)
                        st.plotly_chart(mfcc_fig, use_container_width=True, key="audio_analysis_mfcc")
                    except Exception as e:
                        st.error(f"MFCC„ÅÆË°®Á§∫„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {str(e)}")
                        import traceback
                        with st.expander("Ë©≥Á¥∞„Ç®„É©„ÉºÊÉÖÂ†±"):
                            st.code(traceback.format_exc())
                
                with col2:
                    # Radar chart
                    st.write("**Èü≥Â£∞ÁâπÂæ¥„É¨„Éº„ÉÄ„Éº„ÉÅ„É£„Éº„Éà**")
                    try:
                        radar_fig = self.viz_manager.create_audio_features_radar(st.session_state.audio_features)
                        st.plotly_chart(radar_fig, use_container_width=True, key="audio_analysis_radar")
                    except Exception as e:
                        st.error(f"„É¨„Éº„ÉÄ„Éº„ÉÅ„É£„Éº„Éà„ÅÆË°®Á§∫„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {str(e)}")
                        import traceback
                        with st.expander("Ë©≥Á¥∞„Ç®„É©„ÉºÊÉÖÂ†±"):
                            st.code(traceback.format_exc())
                
                # Comprehensive dashboard
                st.subheader("üìä Á∑èÂêàÂàÜÊûê„ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„Éâ")
                try:
                    dashboard_fig = self.viz_manager.create_audio_analysis_dashboard(
                        st.session_state.audio_path, 
                        st.session_state.audio_features
                    )
                    st.plotly_chart(dashboard_fig, use_container_width=True, key="audio_analysis_dashboard")
                except Exception as e:
                    st.error(f"„ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„Éâ„ÅÆË°®Á§∫„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {str(e)}")
                    import traceback
                    with st.expander("Ë©≥Á¥∞„Ç®„É©„ÉºÊÉÖÂ†±"):
                        st.code(traceback.format_exc())
                        
            except Exception as e:
                st.error(f"Èü≥Â£∞ÂàÜÊûê„ÅÆË°®Á§∫„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {str(e)}")
                import traceback
                with st.expander("Ë©≥Á¥∞„Ç®„É©„ÉºÊÉÖÂ†±"):
                    st.code(traceback.format_exc())
        else:
            st.warning("‚ö†Ô∏è Èü≥Â£∞„Éï„Ç°„Ç§„É´„ÅåË™≠„ÅøËæº„Åæ„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ„Çµ„Ç§„Éâ„Éê„Éº„ÅßÈü≥Â£∞„Éï„Ç°„Ç§„É´„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åæ„Åü„ÅØ„Çµ„É≥„Éó„É´Èü≥Â£∞„ÇíÈÅ∏Êäû„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
    
    def _display_text_audio_matching_tab(self):
        """Display text-audio matching tab"""
        st.header("üîç „ÉÜ„Ç≠„Çπ„Éà-Èü≥Â£∞„Éû„ÉÉ„ÉÅ„É≥„Ç∞")
        
        # Check if model and audio are loaded
        if not st.session_state.model_loaded:
            st.warning("‚ö†Ô∏è CLAP„É¢„Éá„É´„ÅåË™≠„ÅøËæº„Åæ„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ„Çµ„Ç§„Éâ„Éê„Éº„ÅßCLAP„É¢„Éá„É´„ÇíË™≠„ÅøËæº„Çì„Åß„Åè„Å†„Åï„ÅÑ„ÄÇ")
            return
        
        if not st.session_state.audio_path:
            st.warning("‚ö†Ô∏è Èü≥Â£∞„Éï„Ç°„Ç§„É´„ÅåË™≠„ÅøËæº„Åæ„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ„Çµ„Ç§„Éâ„Éê„Éº„ÅßÈü≥Â£∞„Éï„Ç°„Ç§„É´„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
            return
        
        # Custom text input
        st.subheader("üìù „Ç´„Çπ„Çø„É†„ÇØ„Ç®„É™")
        
        col1, col2 = st.columns([3, 1])
        
        with col1:
            custom_text = st.text_input(
                "„ÉÜ„Ç≠„Çπ„Éà„ÇØ„Ç®„É™„ÇíÂÖ•Âäõ",
                placeholder="‰æã: Èü≥Ê•Ω„ÅåÊµÅ„Çå„Å¶„ÅÑ„Çã„ÄÅ‰∫∫„ÅÆË©±„ÅóÂ£∞„ÄÅÈ≥•„ÅÆÈ≥¥„ÅçÂ£∞...",
                key="matching_custom_text"
            )
        
        with col2:
            if st.button("ÂàÜÊûêÂÆüË°å", type="primary"):
                if custom_text:
                    self._analyze_single_query_with_success_detection(custom_text)
                else:
                    st.error("„ÉÜ„Ç≠„Çπ„Éà„ÇØ„Ç®„É™„ÇíÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
        
        # Display similarity results with success analysis
        if st.session_state.similarity_results:
            self._display_matching_results_with_analysis()
    
    def _analyze_single_query_with_success_detection(self, text_query: str):
        """Analyze single text query with success detection
        
        Args:
            text_query: Single text query to analyze
        """
        if not st.session_state.audio_path or not st.session_state.model_loaded:
            return
        
        with st.spinner("„ÉÜ„Ç≠„Çπ„Éà-Èü≥Â£∞„Éû„ÉÉ„ÉÅ„É≥„Ç∞„ÇíÂàÜÊûê‰∏≠..."):
            start_time = time.time()
            
            # Perform audio-text matching
            results = self.clap_manager.audio_text_matching(
                st.session_state.audio_path,
                [text_query]
            )
            
            processing_time = time.time() - start_time
            st.session_state.processing_times["Single Query Analysis"] = processing_time
            
            # Update results
            st.session_state.similarity_results.update(results)
            
            # Perform success analysis
            success_analysis = self._analyze_matching_success(results, text_query)
            st.session_state.matching_success_analysis = success_analysis
            
            st.success(f"‚úÖ ÂàÜÊûêÂÆå‰∫Ü ({processing_time:.2f}Áßí)")
    
    def _analyze_matching_success(self, similarity_scores: Dict[str, float], main_query: str) -> Dict[str, Any]:
        """Analyze matching success based on similarity scores
        
        Args:
            similarity_scores: Dictionary of query to similarity score
            main_query: Main query that was analyzed
            
        Returns:
            Dict[str, Any]: Success analysis results
        """
        if not similarity_scores:
            return {
                "is_successful": False,
                "confidence_level": "none",
                "best_score": 0.0,
                "main_query_score": 0.0,
                "success_reason": "„Éû„ÉÉ„ÉÅ„É≥„Ç∞ÁµêÊûú„Åå„ÅÇ„Çä„Åæ„Åõ„Çì"
            }
        
        # Get main query score
        main_query_score = similarity_scores.get(main_query, 0.0)
        
        # Get best score
        best_score = max(similarity_scores.values())
        best_query = max(similarity_scores.items(), key=lambda x: x[1])[0]
        
        # Define success thresholds
        success_thresholds = {
            "excellent": 0.7,    # ÂÑ™ÁßÄ„Å™„Éû„ÉÉ„ÉÅ„É≥„Ç∞
            "good": 0.5,         # ËâØÂ•Ω„Å™„Éû„ÉÉ„ÉÅ„É≥„Ç∞
            "fair": 0.3,         # ÊôÆÈÄö„ÅÆ„Éû„ÉÉ„ÉÅ„É≥„Ç∞
            "poor": 0.1          # Ë≤ßÂº±„Å™„Éû„ÉÉ„ÉÅ„É≥„Ç∞
        }
        
        # Determine confidence level
        confidence_level = "none"
        if best_score >= success_thresholds["excellent"]:
            confidence_level = "excellent"
        elif best_score >= success_thresholds["good"]:
            confidence_level = "good"
        elif best_score >= success_thresholds["fair"]:
            confidence_level = "fair"
        elif best_score >= success_thresholds["poor"]:
            confidence_level = "poor"
        
        # Determine if matching is successful
        is_successful = best_score >= success_thresholds["fair"]
        
        # Generate success reason
        success_reason = self._generate_matching_success_reason(
            is_successful, confidence_level, best_score, main_query_score, best_query
        )
        
        return {
            "is_successful": is_successful,
            "confidence_level": confidence_level,
            "best_score": best_score,
            "best_query": best_query,
            "main_query_score": main_query_score,
            "success_thresholds": success_thresholds,
            "success_reason": success_reason
        }
    
    def _generate_matching_success_reason(self, is_successful: bool, confidence_level: str,
                                        best_score: float, main_query_score: float, 
                                        best_query: str) -> str:
        """Generate human-readable matching success reason
        
        Args:
            is_successful: Whether matching was successful
            confidence_level: Confidence level
            best_score: Best similarity score
            main_query_score: Main query score
            best_query: Best matching query
            
        Returns:
            str: Success reason
        """
        if not is_successful:
            return f"„Éû„ÉÉ„ÉÅ„É≥„Ç∞„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇÊúÄÈ´ò„Çπ„Ç≥„Ç¢: {best_score:.3f} (ÈñæÂÄ§: 0.3)"
        
        reasons = []
        
        if confidence_level == "excellent":
            reasons.append("ÂÑ™ÁßÄ„Å™„Éû„ÉÉ„ÉÅ„É≥„Ç∞")
        elif confidence_level == "good":
            reasons.append("ËâØÂ•Ω„Å™„Éû„ÉÉ„ÉÅ„É≥„Ç∞")
        elif confidence_level == "fair":
            reasons.append("ÊôÆÈÄö„ÅÆ„Éû„ÉÉ„ÉÅ„É≥„Ç∞")
        
        if best_score > 0.8:
            reasons.append("ÈùûÂ∏∏„Å´È´ò„ÅÑÈ°û‰ººÂ∫¶")
        elif best_score > 0.6:
            reasons.append("È´ò„ÅÑÈ°û‰ººÂ∫¶")
        
        if main_query_score == best_score:
            reasons.append("„É°„Ç§„É≥„ÇØ„Ç®„É™„ÅåÊúÄÈÅ©„Éû„ÉÉ„ÉÅ")
        
        return " | ".join(reasons) if reasons else "„Éû„ÉÉ„ÉÅ„É≥„Ç∞ÊàêÂäü"
    
    def _display_matching_results_with_analysis(self):
        """Display matching results with success analysis"""
        results = st.session_state.similarity_results
        success_analysis = st.session_state.get("matching_success_analysis", {})
        
        # Success analysis display
        if success_analysis:
            st.subheader("üìä „Éû„ÉÉ„ÉÅ„É≥„Ç∞ÊàêÂäüÂàÜÊûê")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                # Success status
                if success_analysis.get("is_successful", False):
                    st.success("‚úÖ „Éû„ÉÉ„ÉÅ„É≥„Ç∞ÊàêÂäü")
                else:
                    st.error("‚ùå „Éû„ÉÉ„ÉÅ„É≥„Ç∞Â§±Êïó")
            
            with col2:
                # Confidence level
                confidence_level = success_analysis.get("confidence_level", "none")
                if confidence_level == "excellent":
                    st.success(f"üéØ ÂÑ™ÁßÄ ({confidence_level})")
                elif confidence_level == "good":
                    st.info(f"üëç ËâØÂ•Ω ({confidence_level})")
                elif confidence_level == "fair":
                    st.warning(f"‚ö†Ô∏è ÊôÆÈÄö ({confidence_level})")
                else:
                    st.error(f"‚ùå Ë≤ßÂº± ({confidence_level})")
            
            with col3:
                # Best score
                best_score = success_analysis.get("best_score", 0.0)
                st.metric("ÊúÄÈ´ò„Çπ„Ç≥„Ç¢", f"{best_score:.3f}")
            
            with col4:
                # Main query score
                main_query_score = success_analysis.get("main_query_score", 0.0)
                st.metric("„É°„Ç§„É≥„ÇØ„Ç®„É™„Çπ„Ç≥„Ç¢", f"{main_query_score:.3f}")
            
            # Success reason
            success_reason = success_analysis.get("success_reason", "")
            if success_reason:
                st.info(f"**ÂàÜÊûêÁµêÊûú:** {success_reason}")
        
        # Detailed results
        st.subheader("üìà Ë©≥Á¥∞ÁµêÊûú")
        
        # Sort results by similarity score
        sorted_results = sorted(
            results.items(),
            key=lambda x: x[1],
            reverse=True
        )
        
        # Display results with enhanced styling
        for i, (text, score) in enumerate(sorted_results):
            # Determine similarity level and styling
            if score >= 0.7:
                css_class = "high-similarity"
                emoji = "üü¢"
                level_text = "ÂÑ™ÁßÄ"
            elif score >= 0.5:
                css_class = "medium-similarity"
                emoji = "üü°"
                level_text = "ËâØÂ•Ω"
            elif score >= 0.3:
                css_class = "low-similarity"
                emoji = "üü†"
                level_text = "ÊôÆÈÄö"
            else:
                css_class = "low-similarity"
                emoji = "üî¥"
                level_text = "Ë≤ßÂº±"
            
            # Highlight main query
            if success_analysis and text == success_analysis.get("best_query", ""):
                text_display = f"**{text}** (ÊúÄÈÅ©„Éû„ÉÉ„ÉÅ)"
            else:
                text_display = text
            
            st.markdown(f"""
            <div class="similarity-score {css_class}">
                {emoji} <strong>{text_display}</strong>: {score:.3f} ({level_text})
            </div>
            """, unsafe_allow_html=True)
        
        # Similarity chart
        st.subheader("üìä È°û‰ººÂ∫¶„ÉÅ„É£„Éº„Éà")
        similarity_fig = self.viz_manager.create_similarity_bar_chart(results)
        st.plotly_chart(similarity_fig, use_container_width=True, key="matching_similarity_chart")
        
        # Performance metrics
        if st.session_state.processing_times.get("Single Query Analysis"):
            st.subheader("‚è±Ô∏è „Éë„Éï„Ç©„Éº„Éû„É≥„Çπ")
            processing_time = st.session_state.processing_times["Single Query Analysis"]
            st.metric("Âá¶ÁêÜÊôÇÈñì", f"{processing_time:.3f}Áßí")
        
        # Recommendations
        if success_analysis:
            recommendations = self._generate_matching_recommendations(success_analysis)
            if recommendations:
                st.subheader("üí° Êé®Â•®‰∫ãÈ†Ö")
                for recommendation in recommendations:
                    st.write(f"‚Ä¢ {recommendation}")
    
    def _generate_matching_recommendations(self, success_analysis: Dict[str, Any]) -> List[str]:
        """Generate recommendations based on matching success analysis
        
        Args:
            success_analysis: Success analysis results
            
        Returns:
            List[str]: List of recommendations
        """
        recommendations = []
        
        if not success_analysis.get("is_successful", False):
            recommendations.append("„Çà„ÇäÂÖ∑‰ΩìÁöÑ„Å™„ÉÜ„Ç≠„Çπ„Éà„ÇØ„Ç®„É™„ÇíË©¶„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
            recommendations.append("Èü≥Â£∞„ÅÆÁâπÂæ¥„ÇíË©≥„Åó„ÅèË™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
            recommendations.append("Ë§áÊï∞„ÅÆ„Ç≠„Éº„ÉØ„Éº„Éâ„ÇíÁµÑ„ÅøÂêà„Çè„Åõ„Å¶„Åø„Å¶„Åè„Å†„Åï„ÅÑ")
        
        confidence_level = success_analysis.get("confidence_level", "none")
        if confidence_level == "poor":
            recommendations.append("„Éû„ÉÉ„ÉÅ„É≥„Ç∞ÁµêÊûú„ÅÆ‰ø°È†ºÂ∫¶„Åå‰Ωé„ÅÑ„Åß„Åô„ÄÇÂà•„ÅÆË°®Áèæ„ÇíË©¶„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
        
        best_score = success_analysis.get("best_score", 0.0)
        if best_score < 0.5:
            recommendations.append("È°û‰ººÂ∫¶„Åå‰Ωé„ÅÑ„Åü„ÇÅ„ÄÅ„Çà„ÇäÈÅ©Âàá„Å™„ÇØ„Ç®„É™„ÇíÊ§úË®é„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
        
        return recommendations
    
    def _display_visualization_tab(self):
        """Display visualization tab"""
        st.header("üìä ÂèØË¶ñÂåñ")
        
        if st.session_state.audio_path and st.session_state.audio_features:
            try:
                # Comprehensive dashboard
                st.subheader("üéõÔ∏è Èü≥Â£∞ÂàÜÊûê„ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„Éâ")
                try:
                    dashboard_fig = self.viz_manager.create_audio_analysis_dashboard(
                        st.session_state.audio_path,
                        st.session_state.audio_features
                    )
                    st.plotly_chart(dashboard_fig, use_container_width=True, key="visualization_dashboard")
                except Exception as e:
                    st.error(f"„ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„Éâ„ÅÆË°®Á§∫„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {str(e)}")
                    import traceback
                    with st.expander("Ë©≥Á¥∞„Ç®„É©„ÉºÊÉÖÂ†±"):
                        st.code(traceback.format_exc())
                
                # Individual visualizations
                st.subheader("üìà ÂÄãÂà•ÂèØË¶ñÂåñ")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write("**Ê≥¢ÂΩ¢Ë°®Á§∫**")
                    try:
                        waveform_fig = self.viz_manager.create_audio_waveform(st.session_state.audio_path)
                        st.plotly_chart(waveform_fig, use_container_width=True, key="visualization_waveform")
                    except Exception as e:
                        st.error(f"Ê≥¢ÂΩ¢„ÅÆË°®Á§∫„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {str(e)}")
                        import traceback
                        with st.expander("Ë©≥Á¥∞„Ç®„É©„ÉºÊÉÖÂ†±"):
                            st.code(traceback.format_exc())
                
                with col2:
                    st.write("**„Çπ„Éö„ÇØ„Éà„É≠„Ç∞„É©„É†**")
                    try:
                        spectrogram_fig = self.viz_manager.create_spectrogram(st.session_state.audio_path)
                        st.plotly_chart(spectrogram_fig, use_container_width=True, key="visualization_spectrogram")
                    except Exception as e:
                        st.error(f"„Çπ„Éö„ÇØ„Éà„É≠„Ç∞„É©„É†„ÅÆË°®Á§∫„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {str(e)}")
                        import traceback
                        with st.expander("Ë©≥Á¥∞„Ç®„É©„ÉºÊÉÖÂ†±"):
                            st.code(traceback.format_exc())
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write("**MFCCÁâπÂæ¥Èáè**")
                    try:
                        mfcc_fig = self.viz_manager.create_mfcc_heatmap(st.session_state.audio_path)
                        st.plotly_chart(mfcc_fig, use_container_width=True, key="visualization_mfcc")
                    except Exception as e:
                        st.error(f"MFCC„ÅÆË°®Á§∫„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {str(e)}")
                        import traceback
                        with st.expander("Ë©≥Á¥∞„Ç®„É©„ÉºÊÉÖÂ†±"):
                            st.code(traceback.format_exc())
                
                with col2:
                    st.write("**Èü≥Â£∞ÁâπÂæ¥„É¨„Éº„ÉÄ„Éº„ÉÅ„É£„Éº„Éà**")
                    try:
                        radar_fig = self.viz_manager.create_audio_features_radar(st.session_state.audio_features)
                        st.plotly_chart(radar_fig, use_container_width=True, key="visualization_radar")
                    except Exception as e:
                        st.error(f"„É¨„Éº„ÉÄ„Éº„ÉÅ„É£„Éº„Éà„ÅÆË°®Á§∫„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {str(e)}")
                        import traceback
                        with st.expander("Ë©≥Á¥∞„Ç®„É©„ÉºÊÉÖÂ†±"):
                            st.code(traceback.format_exc())
                
            except Exception as e:
                st.error(f"ÂèØË¶ñÂåñ„ÅÆË°®Á§∫„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {str(e)}")
                import traceback
                with st.expander("Ë©≥Á¥∞„Ç®„É©„ÉºÊÉÖÂ†±"):
                    st.code(traceback.format_exc())
        else:
            st.warning("‚ö†Ô∏è Èü≥Â£∞„Éï„Ç°„Ç§„É´„ÅåË™≠„ÅøËæº„Åæ„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ„Çµ„Ç§„Éâ„Éê„Éº„ÅßÈü≥Â£∞„Éï„Ç°„Ç§„É´„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åæ„Åü„ÅØ„Çµ„É≥„Éó„É´Èü≥Â£∞„ÇíÈÅ∏Êäû„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
    
    def _display_timing_analysis_tab(self):
        """Display timing analysis tab"""
        st.header("‚è±Ô∏è Ê§úÂá∫„Çø„Ç§„Éü„É≥„Ç∞ÂàÜÊûê")
        
        if st.session_state.detection_timing_data:
            timing_data = st.session_state.detection_timing_data
            
            # Summary table
            st.subheader("üìã Ê§úÂá∫ÁµêÊûú„Çµ„Éû„É™„Éº")
            summary_fig = self.viz_manager.create_detection_summary_table(timing_data)
            st.plotly_chart(summary_fig, use_container_width=True, key="timing_summary")
            
            # Detailed timing analysis
            st.subheader("üìä Ë©≥Á¥∞„Çø„Ç§„Éü„É≥„Ç∞ÂàÜÊûê")
            timing_fig = self.viz_manager.create_detection_timing_analysis(timing_data)
            st.plotly_chart(timing_fig, use_container_width=True, key="timing_analysis")
            
            # Timing details
            st.subheader("üîç „Çø„Ç§„Éü„É≥„Ç∞Ë©≥Á¥∞")
            timing = timing_data.get("timing", {})
            audio_info = timing_data.get("audio_info", {})
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Á∑èÂá¶ÁêÜÊôÇÈñì", f"{timing.get('total_time', 0):.3f}Áßí")
                st.metric("Èü≥Â£∞Âá¶ÁêÜÊôÇÈñì", f"{timing.get('audio_processing_time', 0):.3f}Áßí")
            with col2:
                st.metric("„ÉÜ„Ç≠„Çπ„ÉàÂá¶ÁêÜÊôÇÈñì", f"{timing.get('text_processing_time', 0):.3f}Áßí")
                st.metric("Èü≥Â£∞Èï∑", f"{audio_info.get('duration', 0):.2f}Áßí")
            with col3:
                # Âá¶ÁêÜÂäπÁéá„ÅÆË®àÁÆóÔºà„Çº„É≠Èô§ÁÆó„ÇíÈò≤„ÅêÔºâ
                total_time = timing.get('total_time', 0)
                audio_duration = audio_info.get('duration', 0)
                if total_time > 0:
                    efficiency = audio_duration / total_time
                    st.metric("Âá¶ÁêÜÂäπÁéá", f"{efficiency:.2f}x")
                else:
                    st.metric("Âá¶ÁêÜÂäπÁéá", "N/A")
                st.metric("„ÇØ„Ç®„É™Êï∞", len(timing_data.get("similarities", {})))
            
            # Per query timing details
            if timing.get("per_query_times"):
                st.subheader("üìà „ÇØ„Ç®„É™Âà•Âá¶ÁêÜÊôÇÈñì")
                per_query_data = timing["per_query_times"]
                
                query_df = pd.DataFrame([
                    {
                        "„ÇØ„Ç®„É™": query,
                        "Á∑èÊôÇÈñì": data.get("total_time", 0),
                        "È°û‰ººÂ∫¶Ë®àÁÆóÊôÇÈñì": data.get("similarity_time", 0),
                        "È°û‰ººÂ∫¶„Çπ„Ç≥„Ç¢": timing_data["similarities"].get(query, 0)
                    }
                    for query, data in per_query_data.items()
                ])
                
                st.dataframe(query_df, use_container_width=True)
        else:
            st.warning("‚ö†Ô∏è Ë©≥Á¥∞ÂàÜÊûê„Éá„Éº„Çø„Åå„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ„Çµ„Ç§„Éâ„Éê„Éº„Åß„ÄåË©≥Á¥∞ÂàÜÊûê„Äç„ÇíÂÆüË°å„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
    
    def _display_audio_search_tab(self):
        """Display audio search tab"""
        st.header("üîé Èü≥Â£∞Ê§úÁ¥¢")
        
        # Check if model is loaded
        if not st.session_state.model_loaded:
            st.warning("‚ö†Ô∏è CLAP„É¢„Éá„É´„ÅåË™≠„ÅøËæº„Åæ„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ„Çµ„Ç§„Éâ„Éê„Éº„ÅßCLAP„É¢„Éá„É´„ÇíË™≠„ÅøËæº„Çì„Åß„Åè„Å†„Åï„ÅÑ„ÄÇ")
            return
        
        # Initialize search engine if needed
        if self.search_engine is None and not st.session_state.search_engine_initialized:
            try:
                from clap_model import AudioSearchEngine
                self.search_engine = AudioSearchEngine(self.clap_manager)
                st.session_state.search_engine_initialized = True
                st.success("üîç Èü≥Â£∞Ê§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅåÂàùÊúüÂåñ„Åï„Çå„Åæ„Åó„Åü")
            except Exception as e:
                st.error(f"‚ùå Ê§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅÆÂàùÊúüÂåñ„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {str(e)}")
                return
        elif self.search_engine is None and st.session_state.search_engine_initialized:
            # Re-initialize if session state says it's initialized but instance is None
            try:
                from clap_model import AudioSearchEngine
                self.search_engine = AudioSearchEngine(self.clap_manager)
                st.info("üîç Èü≥Â£∞Ê§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÇíÂÜçÂàùÊúüÂåñ„Åó„Åæ„Åó„Åü")
            except Exception as e:
                st.error(f"‚ùå Ê§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅÆÂÜçÂàùÊúüÂåñ„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {str(e)}")
                return
        
        if not st.session_state.audio_path:
            st.warning("‚ö†Ô∏è Èü≥Â£∞„Éï„Ç°„Ç§„É´„ÅåË™≠„ÅøËæº„Åæ„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ„Çµ„Ç§„Éâ„Éê„Éº„ÅßÈü≥Â£∞„Éï„Ç°„Ç§„É´„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
            return
        
        # Search configuration
        st.subheader("‚öôÔ∏è Ê§úÁ¥¢Ë®≠ÂÆö")
        
        col1, col2 = st.columns(2)
        
        with col1:
            include_related = st.checkbox("Èñ¢ÈÄ£„ÇØ„Ç®„É™„ÇíÂê´„ÇÅ„Çã", value=True, 
                                        help="„É°„Ç§„É≥„ÇØ„Ç®„É™„Å´Èñ¢ÈÄ£„Åô„Çã„ÇØ„Ç®„É™„ÇÇÊ§úÁ¥¢„Å´Âê´„ÇÅ„Åæ„Åô")
            category_search = st.checkbox("„Ç´„ÉÜ„Ç¥„É™Ê§úÁ¥¢", value=False,
                                        help="Èü≥Â£∞„Ç´„ÉÜ„Ç¥„É™„Å´Âü∫„Å•„ÅèÊ§úÁ¥¢„ÇíÂÆüË°å„Åó„Åæ„Åô")
        
        with col2:
            # Search statistics
            stats = self.search_engine.get_search_statistics()
            st.info(f"**Ê§úÁ¥¢„Ç®„É≥„Ç∏„É≥Áµ±Ë®à:**\n"
                   f"‚Ä¢ „Ç´„ÉÜ„Ç¥„É™Êï∞: {stats['total_categories']}\n"
                   f"‚Ä¢ Á∑è„ÇØ„Ç®„É™Êï∞: {stats['total_queries']}\n"
                   f"‚Ä¢ ÊàêÂäüÈñæÂÄ§: {stats['success_thresholds']['fair']:.1f}")
        
        # Search input
        st.subheader("üîç Ê§úÁ¥¢„ÇØ„Ç®„É™")
        
        col1, col2 = st.columns([3, 1])
        
        with col1:
            search_query = st.text_input(
                "Ê§úÁ¥¢„Åó„Åü„ÅÑÈü≥Â£∞ÂÜÖÂÆπ„ÇíÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ",
                placeholder="‰æã: Èü≥Ê•Ω„ÅåÊµÅ„Çå„Å¶„ÅÑ„Çã„ÄÅ‰∫∫„ÅÆË©±„ÅóÂ£∞„ÄÅÈ≥•„ÅÆÈ≥¥„ÅçÂ£∞„ÄÅËªä„ÅÆÈü≥..."
            )
        
        with col2:
            if st.button("üîé Ê§úÁ¥¢ÂÆüË°å", type="primary"):
                if search_query:
                    self._perform_audio_search(search_query, include_related, category_search)
                else:
                    st.error("Ê§úÁ¥¢„ÇØ„Ç®„É™„ÇíÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
        
        # Quick search suggestions
        st.subheader("üí° Ê§úÁ¥¢‰æã")
        
        # Category-based suggestions
        stats = self.search_engine.get_search_statistics()
        categories = stats['categories']
        
        selected_category = st.selectbox("„Ç´„ÉÜ„Ç¥„É™„ÇíÈÅ∏Êäû„Åó„Å¶Ê§úÁ¥¢‰æã„ÇíË°®Á§∫", ["„Åô„Åπ„Å¶"] + categories)
        
        if selected_category != "„Åô„Åπ„Å¶":
            category_queries = self.search_engine.audio_categories[selected_category]
            st.write(f"**{selected_category}„Ç´„ÉÜ„Ç¥„É™„ÅÆÊ§úÁ¥¢‰æã:**")
            
            # Display queries in a grid
            cols = st.columns(3)
            for i, query in enumerate(category_queries[:9]):  # Show first 9 queries
                with cols[i % 3]:
                    if st.button(query, key=f"quick_search_{i}"):
                        self._perform_audio_search(query, include_related, category_search)
        else:
            # Show one example from each category
            st.write("**ÂêÑ„Ç´„ÉÜ„Ç¥„É™„ÅÆÊ§úÁ¥¢‰æã:**")
            cols = st.columns(len(categories))
            for i, category in enumerate(categories):
                with cols[i]:
                    example_query = self.search_engine.audio_categories[category][0]
                    if st.button(example_query, key=f"category_example_{i}"):
                        self._perform_audio_search(example_query, include_related, category_search)
        
        # Display search results
        if st.session_state.search_results:
            self._display_search_results()
    
    def _perform_audio_search(self, search_query: str, include_related: bool, category_search: bool):
        """Perform audio search
        
        Args:
            search_query: Search query
            include_related: Whether to include related queries
            category_search: Whether to search within categories
        """
        with st.spinner("Èü≥Â£∞Ê§úÁ¥¢„ÇíÂÆüË°å‰∏≠..."):
            search_results = self.search_engine.search_audio(
                st.session_state.audio_path,
                search_query,
                include_related=include_related,
                category_search=category_search
            )
            
            st.session_state.search_results = search_results
            st.success(f"Ê§úÁ¥¢ÂÆå‰∫ÜÔºÅÂá¶ÁêÜÊôÇÈñì: {search_results['search_time']:.3f}Áßí")
    
    def _display_search_results(self):
        """Display search results"""
        results = st.session_state.search_results
        
        st.subheader("üìä Ê§úÁ¥¢ÁµêÊûú")
        
        # Success analysis
        success_analysis = results["success_analysis"]
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            # Success status
            if success_analysis["is_successful"]:
                st.success("‚úÖ Ê§úÁ¥¢ÊàêÂäü")
            else:
                st.error("‚ùå Ê§úÁ¥¢Â§±Êïó")
        
        with col2:
            # Confidence level
            confidence_level = success_analysis["confidence_level"]
            if confidence_level == "excellent":
                st.success(f"üéØ ÂÑ™ÁßÄ ({confidence_level})")
            elif confidence_level == "good":
                st.info(f"üëç ËâØÂ•Ω ({confidence_level})")
            elif confidence_level == "fair":
                st.warning(f"‚ö†Ô∏è ÊôÆÈÄö ({confidence_level})")
            else:
                st.error(f"‚ùå Ë≤ßÂº± ({confidence_level})")
        
        with col3:
            # Best score
            best_score = success_analysis["best_score"]
            st.metric("ÊúÄÈ´ò„Çπ„Ç≥„Ç¢", f"{best_score:.3f}")
        
        with col4:
            # Average score
            avg_score = success_analysis["average_score"]
            st.metric("Âπ≥Âùá„Çπ„Ç≥„Ç¢", f"{avg_score:.3f}")
        
        # Success reason
        st.info(f"**Ê§úÁ¥¢ÁµêÊûú„ÅÆË™¨Êòé:** {success_analysis['success_reason']}")
        
        # Detailed results
        st.subheader("üìà Ë©≥Á¥∞ÁµêÊûú")
        
        # Sort results by score
        sorted_results = sorted(
            results["results"].items(),
            key=lambda x: x[1],
            reverse=True
        )
        
        # Display top results
        st.write("**‰∏ä‰ΩçÊ§úÁ¥¢ÁµêÊûú:**")
        for i, (query, score) in enumerate(sorted_results[:10]):  # Show top 10
            # Determine color based on score
            if score >= 0.7:
                color = "üü¢"
            elif score >= 0.5:
                color = "üü°"
            elif score >= 0.3:
                color = "üü†"
            else:
                color = "üî¥"
            
            # Highlight main query
            if query == results["query"]:
                query_display = f"**{query}** („É°„Ç§„É≥„ÇØ„Ç®„É™)"
            else:
                query_display = query
            
            st.write(f"{color} {query_display}: {score:.3f}")
        
        # Category matches
        if results["category_matches"]:
            st.subheader("üè∑Ô∏è „Ç´„ÉÜ„Ç¥„É™„Éû„ÉÉ„ÉÅ")
            
            # Sort categories by score
            sorted_categories = sorted(
                results["category_matches"].items(),
                key=lambda x: x[1],
                reverse=True
            )
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**„Ç´„ÉÜ„Ç¥„É™Âà•„Çπ„Ç≥„Ç¢:**")
                for category, score in sorted_categories:
                    st.write(f"‚Ä¢ {category}: {score:.3f}")
            
            with col2:
                # Create category chart
                import plotly.graph_objects as go
                
                categories = [cat for cat, _ in sorted_categories]
                scores = [score for _, score in sorted_categories]
                
                fig = go.Figure(data=[
                    go.Bar(x=categories, y=scores, marker_color='lightblue')
                ])
                
                fig.update_layout(
                    title="„Ç´„ÉÜ„Ç¥„É™Âà•„Éû„ÉÉ„ÉÅ„É≥„Ç∞„Çπ„Ç≥„Ç¢",
                    xaxis_title="„Ç´„ÉÜ„Ç¥„É™",
                    yaxis_title="„Çπ„Ç≥„Ç¢",
                    height=300
                )
                
                st.plotly_chart(fig, use_container_width=True, key="category_matches_chart")
        
        # Recommendations
        if results["recommendations"]:
            st.subheader("üí° Êé®Â•®‰∫ãÈ†Ö")
            for recommendation in results["recommendations"]:
                st.write(f"‚Ä¢ {recommendation}")
        
        # Raw results (expandable)
        with st.expander("üîç Áîü„Éá„Éº„Çø"):
            st.json(results)
    
    def _display_debug_tab(self):
        """Display debug information tab"""
        st.header("‚öôÔ∏è „Éá„Éê„ÉÉ„Ç∞ÊÉÖÂ†±")
        
        # Model information
        st.subheader("ü§ñ „É¢„Éá„É´ÊÉÖÂ†±")
        model_info = self.clap_manager.get_model_info()
        model_info_fig = self.viz_manager.create_model_info_display(model_info)
        st.plotly_chart(model_info_fig, use_container_width=True, key="debug_model_info")
        
        # Performance metrics
        if st.session_state.processing_times:
            st.subheader("‚è±Ô∏è Âá¶ÁêÜÊôÇÈñì")
            performance_fig = self.viz_manager.create_performance_metrics(st.session_state.processing_times)
            st.plotly_chart(performance_fig, use_container_width=True, key="debug_performance")
        
        # Audio features details
        if st.session_state.audio_features:
            st.subheader("üéµ Èü≥Â£∞ÁâπÂæ¥Ë©≥Á¥∞")
            st.json(st.session_state.audio_features)
        
        # Search engine information
        if self.search_engine:
            st.subheader("üîç Ê§úÁ¥¢„Ç®„É≥„Ç∏„É≥ÊÉÖÂ†±")
            search_stats = self.search_engine.get_search_statistics()
            st.json(search_stats)
        
        # Matching success analysis
        if st.session_state.matching_success_analysis:
            st.subheader("üéØ „Éû„ÉÉ„ÉÅ„É≥„Ç∞ÊàêÂäüÂàÜÊûê")
            st.json(st.session_state.matching_success_analysis)
    
    def _analyze_audio_text_similarity(self, text_queries: List[str]):
        """Analyze similarity between audio and text queries
        
        Args:
            text_queries: List of text queries to analyze
        """
        if not st.session_state.audio_path or not st.session_state.model_loaded:
            return
        
        with st.spinner("Èü≥Â£∞-„ÉÜ„Ç≠„Çπ„ÉàÈ°û‰ººÂ∫¶„ÇíÂàÜÊûê‰∏≠..."):
            start_time = time.time()
            
            # Perform audio-text matching
            results = self.clap_manager.audio_text_matching(
                st.session_state.audio_path,
                text_queries
            )
            
            processing_time = time.time() - start_time
            st.session_state.processing_times["Audio-Text Matching"] = processing_time
            
            # Store results
            st.session_state.similarity_results = results
            
            st.success(f"‚úÖ ÂàÜÊûêÂÆå‰∫Ü ({processing_time:.2f}Áßí)")
    
    def _analyze_single_query(self, text_query: str):
        """Analyze single text query
        
        Args:
            text_query: Single text query to analyze
        """
        if not st.session_state.audio_path or not st.session_state.model_loaded:
            return
        
        with st.spinner("Âçò‰∏Ä„ÇØ„Ç®„É™„ÇíÂàÜÊûê‰∏≠..."):
            start_time = time.time()
            
            # Perform audio-text matching
            results = self.clap_manager.audio_text_matching(
                st.session_state.audio_path,
                [text_query]
            )
            
            processing_time = time.time() - start_time
            st.session_state.processing_times["Single Query Analysis"] = processing_time
            
            # Update results
            st.session_state.similarity_results.update(results)
            
            st.success(f"‚úÖ ÂàÜÊûêÂÆå‰∫Ü ({processing_time:.2f}Áßí)")
    
    def _analyze_audio_text_similarity_with_timing(self, text_queries: List[str]):
        """Analyze similarity between audio and text queries with detailed timing
        
        Args:
            text_queries: List of text queries to analyze
        """
        if not st.session_state.audio_path or not st.session_state.model_loaded:
            return
        
        with st.spinner("Èü≥Â£∞-„ÉÜ„Ç≠„Çπ„ÉàÈ°û‰ººÂ∫¶„ÇíË©≥Á¥∞ÂàÜÊûê‰∏≠..."):
            # Perform audio-text matching with timing
            results = self.clap_manager.audio_text_matching_with_timing(
                st.session_state.audio_path,
                text_queries
            )
            
            # Store results
            st.session_state.detection_timing_data = results
            st.session_state.similarity_results = results.get("similarities", {})
            
            # Store processing times
            timing = results.get("timing", {})
            st.session_state.processing_times.update({
                "Total Detection Time": timing.get("total_time", 0),
                "Audio Processing": timing.get("audio_processing_time", 0),
                "Text Processing": timing.get("text_processing_time", 0)
            })
            
            st.success(f"‚úÖ Ë©≥Á¥∞ÂàÜÊûêÂÆå‰∫Ü (Á∑èÊôÇÈñì: {timing.get('total_time', 0):.2f}Áßí)")
    
    def _load_sample_audio(self, audio_name: str):
        """Load sample audio file
        
        Args:
            audio_name: Name of the sample audio to load
        """
        try:
            with st.spinner(f"{audio_name} „Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ‰∏≠..."):
                audio_path = self.sample_audio_manager.download_sample_audio(audio_name)
                
                if audio_path:
                    st.session_state.audio_path = audio_path
                    
                    # Load audio for display
                    import requests
                    sample_info = self.sample_audio_manager.get_sample_audio_info(audio_name)
                    if sample_info:
                        response = requests.get(sample_info["url"])
                        if response.status_code == 200:
                            st.sidebar.audio(response.content, format="audio/wav")
                    
                    # Update audio features
                    audio_info = self.audio_analyzer.analyze_audio_file(audio_path)
                    if audio_info:
                        st.session_state.audio_features = audio_info
                    
                    st.sidebar.success(f"‚úÖ {audio_name} „ÇíË™≠„ÅøËæº„Åø„Åæ„Åó„ÅüÔºÅ")
                else:
                    st.sidebar.error(f"‚ùå {audio_name} „ÅÆË™≠„ÅøËæº„Åø„Å´Â§±Êïó„Åó„Åæ„Åó„Åü")
        except Exception as e:
            st.sidebar.error(f"‚ùå „Ç®„É©„Éº: {str(e)}")
    
    def _create_synthetic_audio(self, audio_type: str = None, duration: float = 3.0):
        """Create synthetic audio for testing
        
        Args:
            audio_type: Type of synthetic audio to create
            duration: Duration in seconds
        """
        if audio_type is None:
            audio_type = "sine_wave"
        
        try:
            with st.spinner(f"{audio_type} „Çí‰ΩúÊàê‰∏≠..."):
                audio_path = self.sample_audio_manager.create_synthetic_audio(
                    audio_type, duration
                )
                
                if audio_path:
                    st.session_state.audio_path = audio_path
                    
                    # Load audio for display
                    with open(audio_path, 'rb') as f:
                        audio_data = f.read()
                    st.sidebar.audio(audio_data, format="audio/wav")
                    
                    # Update audio features
                    audio_info = self.audio_analyzer.analyze_audio_file(audio_path)
                    if audio_info:
                        st.session_state.audio_features = audio_info
                    
                    st.sidebar.success(f"‚úÖ {audio_type} „Çí‰ΩúÊàê„Åó„Åæ„Åó„ÅüÔºÅ")
                else:
                    st.sidebar.error(f"‚ùå {audio_type} „ÅÆ‰ΩúÊàê„Å´Â§±Êïó„Åó„Åæ„Åó„Åü")
        except Exception as e:
            st.sidebar.error(f"‚ùå „Ç®„É©„Éº: {str(e)}")


def main():
    """Main function"""
    app = CLAPApp()
    app.run()


if __name__ == "__main__":
    main() 